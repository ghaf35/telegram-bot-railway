#!/usr/bin/env python3
"""
Extension vocale avec OpenAI Whisper pour transcription
"""

import os
import tempfile
import logging
from telegram import Update
from telegram.ext import ContextTypes
from openai import OpenAI
from pydub import AudioSegment

logger = logging.getLogger(__name__)

# Pour utiliser cette version, ajoute OPENAI_API_KEY dans Railway
OPENAI_KEY = os.environ.get("OPENAI_API_KEY")

async def handle_voice_with_whisper(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """G√©rer les messages vocaux avec transcription Whisper"""
    if not OPENAI_KEY:
        await update.message.reply_text(
            "üé§ *Fonction vocale*\n\n"
            "Pour activer la transcription, ajoute `OPENAI_API_KEY` dans Railway.\n\n"
            "En attendant, utilise la transcription native Telegram :\n"
            "‚Ä¢ Maintiens le micro\n"
            "‚Ä¢ Glisse vers le haut\n"
            "‚Ä¢ Le texte appara√Æt automatiquement !",
            parse_mode='Markdown'
        )
        return
    
    logger.info("Message vocal re√ßu - Transcription Whisper")
    
    # Message d'attente
    processing_msg = await update.message.reply_text(
        "üé§ *Transcription en cours...*",
        parse_mode='Markdown'
    )
    
    try:
        # Initialiser OpenAI
        client = OpenAI(api_key=OPENAI_KEY)
        
        # T√©l√©charger le fichier audio
        voice = update.message.voice
        file_id = voice.file_id
        
        # Obtenir le fichier
        new_file = await context.bot.get_file(file_id)
        
        # Cr√©er des fichiers temporaires
        with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as tmp_ogg:
            await new_file.download_to_drive(tmp_ogg.name)
            ogg_path = tmp_ogg.name
        
        # Convertir en MP3 (Whisper pr√©f√®re MP3)
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_mp3:
            mp3_path = tmp_mp3.name
        
        # Conversion avec pydub
        audio = AudioSegment.from_ogg(ogg_path)
        audio.export(mp3_path, format="mp3")
        
        # Transcrire avec Whisper
        with open(mp3_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="fr"  # Fran√ßais par d√©faut
            )
        
        # Nettoyer les fichiers
        os.unlink(ogg_path)
        os.unlink(mp3_path)
        
        # R√©cup√©rer le texte transcrit
        text = transcript.text.strip()
        
        if text:
            # Supprimer le message d'attente
            await processing_msg.delete()
            
            # Afficher la transcription
            await update.message.reply_text(
                f"üé§ *Transcription :*\n_{text}_",
                parse_mode='Markdown'
            )
            
            # Traiter comme une question normale
            # (Appeler la fonction answer_question avec le texte)
            update.message.text = text
            await answer_question(update, context)
        else:
            await processing_msg.edit_text(
                "‚ùå *Aucun texte d√©tect√©*\n\n"
                "_R√©essaie en parlant plus clairement_",
                parse_mode='Markdown'
            )
            
    except Exception as e:
        logger.error(f"Erreur transcription Whisper: {e}")
        await processing_msg.edit_text(
            "‚ùå *Erreur de transcription*\n\n"
            "üí° _Utilise plut√¥t la transcription native Telegram :_\n"
            "‚Ä¢ Maintiens le micro et glisse vers le haut",
            parse_mode='Markdown'
        )

# Note: Pour activer cette version :
# 1. Ajoute OPENAI_API_KEY dans Railway
# 2. Ajoute ces d√©pendances dans requirements.txt :
#    - openai
#    - pydub
#    - ffmpeg-python
# 3. Remplace handle_voice par handle_voice_with_whisper dans le handler
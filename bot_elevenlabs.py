#!/usr/bin/env python3
"""
Bot Telegram avec synth√®se vocale ElevenLabs
"""

import os
import sys
import logging
import requests
import tempfile
import io
import asyncio
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from mistralai import Mistral
import PyPDF2
from elevenlabs import VoiceSettings, play, save
from elevenlabs.client import ElevenLabs

# Configuration du logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Configuration
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
MISTRAL_KEY = os.environ.get("MISTRAL_API_KEY")
ELEVENLABS_API_KEY = os.environ.get("ELEVENLABS_API_KEY")
ELEVENLABS_AGENT_ID = os.environ.get("ELEVENLABS_AGENT_ID")
GITHUB_REPO = os.environ.get("GITHUB_REPO", "ghaf35/mes-cours")

# V√©rifier la config
if not all([TELEGRAM_TOKEN, MISTRAL_KEY, ELEVENLABS_API_KEY]):
    logger.error("‚ùå Variables manquantes ! V√©rifie TELEGRAM_BOT_TOKEN, MISTRAL_API_KEY et ELEVENLABS_API_KEY")
    sys.exit(1)

logger.info(f"‚úÖ Configuration OK - Repo: {GITHUB_REPO}")
logger.info(f"‚úÖ ElevenLabs API Key: {ELEVENLABS_API_KEY[:10]}...") # Affiche les 10 premiers caract√®res
logger.info(f"‚úÖ Agent ID: {ELEVENLABS_AGENT_ID if ELEVENLABS_AGENT_ID else 'Non d√©fini'}")

# Initialiser les clients
try:
    mistral_client = Mistral(api_key=MISTRAL_KEY)
    elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
    logger.info("‚úÖ Mistral et ElevenLabs initialis√©s")
except Exception as e:
    logger.error(f"‚ùå Erreur initialisation: {e}")
    sys.exit(1)

# Cache des documents
documents_cache = {}

# Fonction pour g√©n√©rer de l'audio avec ElevenLabs
async def generate_audio(text: str, voice_id: str = None) -> bytes:
    """G√©n√©rer un audio √† partir du texte avec ElevenLabs"""
    try:
        # Utiliser l'agent ID si disponible, sinon la voix par d√©faut
        if ELEVENLABS_AGENT_ID:
            voice_id = ELEVENLABS_AGENT_ID
        elif not voice_id:
            voice_id = "21m00Tcm4TlvDq8ikWAM"  # Rachel voice par d√©faut
        
        logger.info(f"G√©n√©ration audio avec voice_id: {voice_id}")
        # Nettoyer le texte des emojis et markdown
        clean_text = text.replace("*", "").replace("_", "").replace("`", "")
        # Garder seulement les caract√®res ASCII et fran√ßais
        clean_text = ''.join(char for char in clean_text if ord(char) < 128 or char in '√†√¢√§√©√®√™√´√Ø√Æ√¥√π√ª√º√ø√ß√Ä√Ç√Ñ√â√à√ä√ã√è√é√î√ô√õ√ú≈∏√á')
        
        # Limiter la longueur (ElevenLabs a une limite)
        if len(clean_text) > 2500:
            clean_text = clean_text[:2500] + "..."
        
        logger.info(f"Texte √† convertir ({len(clean_text)} caract√®res): {clean_text[:100]}...")
        
        # Utiliser le SDK ElevenLabs correctement
        try:
            # G√©n√©rer l'audio avec le SDK
            audio_generator = elevenlabs_client.text_to_speech.convert(
                text=clean_text,
                voice_id=voice_id,
                model_id="eleven_multilingual_v2",
                voice_settings=VoiceSettings(
                    stability=0.5,
                    similarity_boost=0.75,
                    style=0.0,
                    use_speaker_boost=True
                )
            )
            
            # Convertir en bytes
            audio_bytes = b"".join(audio_generator)
            logger.info("Audio g√©n√©r√© avec succ√®s via SDK")
            return audio_bytes
            
        except Exception as sdk_error:
            logger.error(f"Erreur SDK ElevenLabs: {str(sdk_error)}")
            # Fallback sur l'API HTTP si le SDK √©choue
            import httpx
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": ELEVENLABS_API_KEY
            }
            
            data = {
                "text": clean_text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75
                }
            }
            
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}",
                    headers=headers,
                    json=data,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    logger.info("Audio g√©n√©r√© avec succ√®s via HTTP")
                    return response.content
                else:
                    logger.error(f"Erreur API ElevenLabs: {response.status_code}")
                    logger.error(f"R√©ponse: {response.text}")
                    return None
        
    except Exception as e:
        logger.error(f"Erreur g√©n√©ration audio ElevenLabs: {str(e)}")
        logger.error(f"Type d'erreur: {type(e).__name__}")
        logger.error(f"Voice ID utilis√©: {voice_id}")
        return None

# Commande /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Message de bienvenue avec audio"""
    logger.info(f"Commande /start de {update.effective_user.username}")
    
    message = """
ü§ñ *Salut ! Je suis ton assistant intelligent avec voix !*

Je peux lire tes documents et te r√©pondre en audio üéß

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üéØ *Nouvelles commandes vocales :*
‚Ä¢ `/explain_audio [concept]` ‚Üí Explication audio
‚Ä¢ `/summary_audio [doc]` ‚Üí R√©sum√© vocal
‚Ä¢ `/read [doc]` ‚Üí Lecture du document

üîä *Autres commandes :*
‚Ä¢ `/voice on/off` ‚Üí Activer/d√©sactiver la voix
‚Ä¢ `/sync` ‚Üí Charger tes documents
‚Ä¢ Toutes les commandes classiques !

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üí¨ *Essaie :* `/explain_audio photosynth√®se`
"""
    
    await update.message.reply_text(message, parse_mode='Markdown')
    
    # Envoyer un message de bienvenue audio
    welcome_audio = await generate_audio(
        "Salut ! Je suis ton assistant intelligent avec synth√®se vocale. "
        "Je peux t'expliquer tes cours et te faire des r√©sum√©s audio. "
        "Essaie la commande explain audio pour commencer !"
    )
    
    if welcome_audio:
        await update.message.reply_voice(
            voice=welcome_audio,
            caption="üéß *Message de bienvenue*",
            parse_mode='Markdown'
        )

# Commande /explain_audio
async def explain_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Expliquer un concept avec audio"""
    if not context.args:
        await update.message.reply_text(
            "üéß *Utilisation :* `/explain_audio [concept]`\n\n"
            "Exemples :\n"
            "‚Ä¢ `/explain_audio photosynth√®se`\n"
            "‚Ä¢ `/explain_audio d√©veloppement durable`",
            parse_mode='Markdown'
        )
        return
    
    concept = ' '.join(context.args)
    logger.info(f"Explication audio demand√©e pour : {concept}")
    
    # Message d'attente
    processing_msg = await update.message.reply_text(
        f"üé§ *G√©n√©ration de l'explication audio pour :* `{concept}`\n\n"
        "‚è≥ _Pr√©paration en cours..._",
        parse_mode='Markdown'
    )
    
    try:
        # Chercher le concept dans les documents
        context_text = ""
        if documents_cache:
            for doc_name, content in documents_cache.items():
                if concept.lower() in content.lower():
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if concept.lower() in line.lower():
                            start = max(0, i-2)
                            end = min(len(lines), i+3)
                            context_text += '\n'.join(lines[start:end]) + "\n\n"
                            if len(context_text) > 1000:
                                break
                if len(context_text) > 1000:
                    break
        
        # G√©n√©rer l'explication avec Mistral
        prompt = f"""Explique le concept "{concept}" de mani√®re simple et claire pour un √©l√®ve.
        
{("Contexte trouv√© : " + context_text) if context_text else "Utilise tes connaissances g√©n√©rales."}

IMPORTANT : 
- Fais une explication orale, comme si tu parlais √† l'√©l√®ve
- Pas de formatage markdown, pas d'ast√©risques
- Utilise un langage simple et des exemples concrets
- Maximum 3-4 phrases courtes et claires"""

        response = mistral_client.chat.complete(
            model="mistral-small-latest",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=400,
            temperature=0.3
        )
        
        explanation = response.choices[0].message.content
        
        # G√©n√©rer l'audio
        audio_bytes = await generate_audio(explanation)
        
        if audio_bytes:
            # Mettre √† jour le message
            await processing_msg.edit_text(
                f"‚úÖ *Explication audio de :* `{concept}`\n\n"
                f"üìù _Transcription :_\n{explanation}",
                parse_mode='Markdown'
            )
            
            # Envoyer l'audio
            await update.message.reply_voice(
                voice=audio_bytes,
                caption=f"üéß *{concept}*",
                parse_mode='Markdown'
            )
        else:
            await processing_msg.edit_text(
                "‚ùå *Erreur de g√©n√©ration audio*\n\n"
                f"üìù *Explication texte :*\n{explanation}",
                parse_mode='Markdown'
            )
            
    except Exception as e:
        logger.error(f"Erreur explain_audio: {e}")
        await processing_msg.edit_text(
            "‚ùå *Erreur lors de la g√©n√©ration*\n\n"
            "_Essaie avec `/explain` pour la version texte_",
            parse_mode='Markdown'
        )

# Commande /summary_audio
async def summary_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """R√©sumer un document en audio"""
    if not documents_cache:
        await update.message.reply_text(
            "üìÇ *Aucun document disponible*\n\n"
            "Utilise `/sync` pour charger des documents !",
            parse_mode='Markdown'
        )
        return
    
    if not context.args:
        message = "üéß *Utilisation :* `/summary_audio [nom du document]`\n\n"
        message += "*Documents disponibles :*\n"
        for doc_name in list(documents_cache.keys())[:5]:
            emoji = "üìï" if doc_name.endswith('.pdf') else "üìÑ"
            message += f"{emoji} `{doc_name}`\n"
        await update.message.reply_text(message, parse_mode='Markdown')
        return
    
    # Trouver le document
    doc_name = ' '.join(context.args)
    found_doc = None
    for name in documents_cache.keys():
        if doc_name.lower() in name.lower():
            found_doc = name
            break
    
    if not found_doc:
        await update.message.reply_text(
            f"‚ùå *Document non trouv√© :* `{doc_name}`",
            parse_mode='Markdown'
        )
        return
    
    processing_msg = await update.message.reply_text(
        f"üé§ *G√©n√©ration du r√©sum√© audio pour :* `{found_doc}`\n"
        "‚è≥ _En cours..._",
        parse_mode='Markdown'
    )
    
    try:
        content = documents_cache[found_doc]
        words = len(content.split())
        content_preview = content[:2000] if len(content) > 2000 else content
        
        prompt = f"""Fais un r√©sum√© ORAL et concis de ce document.

IMPORTANT pour le format audio :
- Parle naturellement, comme si tu racontais √† un ami
- Pas de formatage, pas de listes √† puces
- Maximum 5-6 phrases fluides
- Commence par "Ce document parle de..."
- Termine par une phrase de conclusion

Document : {found_doc}
Contenu : {content_preview}"""
        
        response = mistral_client.chat.complete(
            model="mistral-small-latest",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.3
        )
        
        summary = response.choices[0].message.content
        
        # G√©n√©rer l'audio
        audio_bytes = await generate_audio(summary)
        
        if audio_bytes:
            await processing_msg.edit_text(
                f"‚úÖ *R√©sum√© audio de :* `{found_doc}`\n\n"
                f"üìä _Document de {words:,} mots_\n\n"
                f"üìù _Transcription :_\n{summary}",
                parse_mode='Markdown'
            )
            
            await update.message.reply_voice(
                voice=audio_bytes,
                caption=f"üéß *R√©sum√© : {found_doc}*",
                parse_mode='Markdown'
            )
        else:
            await processing_msg.edit_text(
                f"‚ùå *Erreur audio*\n\nüìù *R√©sum√© texte :*\n{summary}",
                parse_mode='Markdown'
            )
            
    except Exception as e:
        logger.error(f"Erreur summary_audio: {e}")
        await processing_msg.edit_text(
            "‚ùå *Erreur*\n_Utilise `/summary` pour la version texte_",
            parse_mode='Markdown'
        )

# Commande /read (lecture compl√®te d'un document)
async def read_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Lire un document entier en audio"""
    if not documents_cache:
        await update.message.reply_text(
            "üìÇ *Aucun document disponible*",
            parse_mode='Markdown'
        )
        return
    
    if not context.args:
        await update.message.reply_text(
            "üìñ *Utilisation :* `/read [nom du document]`\n\n"
            "_Lit les premi√®res lignes du document_",
            parse_mode='Markdown'
        )
        return
    
    doc_name = ' '.join(context.args)
    found_doc = None
    for name in documents_cache.keys():
        if doc_name.lower() in name.lower():
            found_doc = name
            break
    
    if not found_doc:
        await update.message.reply_text(
            f"‚ùå *Document non trouv√© :* `{doc_name}`",
            parse_mode='Markdown'
        )
        return
    
    processing_msg = await update.message.reply_text(
        f"üìñ *Lecture audio de :* `{found_doc}`\n"
        "‚è≥ _Pr√©paration..._",
        parse_mode='Markdown'
    )
    
    try:
        content = documents_cache[found_doc]
        # Limiter √† 1000 caract√®res pour la lecture
        content_to_read = content[:1000] if len(content) > 1000 else content
        
        # Ajouter une intro
        reading_text = f"Lecture du document {found_doc}. {content_to_read}"
        
        audio_bytes = await generate_audio(reading_text)
        
        if audio_bytes:
            await processing_msg.edit_text(
                f"‚úÖ *Lecture du d√©but de :* `{found_doc}`\n\n"
                f"üìè _Extrait de {len(content_to_read)} caract√®res_",
                parse_mode='Markdown'
            )
            
            await update.message.reply_voice(
                voice=audio_bytes,
                caption=f"üìñ *{found_doc}*",
                parse_mode='Markdown'
            )
        else:
            await processing_msg.edit_text("‚ùå *Erreur de lecture*", parse_mode='Markdown')
            
    except Exception as e:
        logger.error(f"Erreur read: {e}")
        await processing_msg.edit_text("‚ùå *Erreur*", parse_mode='Markdown')

# Commande /voice pour activer/d√©sactiver la synth√®se vocale
async def voice_toggle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Activer/d√©sactiver les r√©ponses vocales"""
    if not context.args:
        await update.message.reply_text(
            "üîä *Utilisation :* `/voice on` ou `/voice off`\n\n"
            "_Active ou d√©sactive les r√©ponses vocales automatiques_",
            parse_mode='Markdown'
        )
        return
    
    mode = context.args[0].lower()
    user_id = update.effective_user.id
    
    if mode == "on":
        context.user_data['voice_enabled'] = True
        await update.message.reply_text(
            "‚úÖ *R√©ponses vocales activ√©es !*\n\n"
            "üéß Les commandes `/explain` et `/summary` incluront maintenant de l'audio",
            parse_mode='Markdown'
        )
    elif mode == "off":
        context.user_data['voice_enabled'] = False
        await update.message.reply_text(
            "üîá *R√©ponses vocales d√©sactiv√©es*\n\n"
            "_Utilise les commandes_ `_audio` _pour l'audio √† la demande_",
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            "‚ùå *Option invalide*\n\n"
            "Utilise `/voice on` ou `/voice off`",
            parse_mode='Markdown'
        )

# Importer les fonctions du bot principal
from bot_railway import (
    sync_github, list_docs, search_in_docs, analyze_docs,
    quiz_command, flashcards_command, explain_command, 
    mindmap_command, answer_question, handle_voice
)

# Version modifi√©e de summary pour inclure l'audio si activ√©
async def summary_with_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """R√©sum√© avec option vocale"""
    # D'abord faire le r√©sum√© texte normal
    from bot_railway import summary_doc
    await summary_doc(update, context)
    
    # Si la voix est activ√©e, ajouter l'audio
    if context.user_data.get('voice_enabled', False) and context.args:
        await summary_audio(update, context)

# Version modifi√©e d'explain pour inclure l'audio si activ√©  
async def explain_with_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Explication avec option vocale"""
    # D'abord faire l'explication texte
    await explain_command(update, context)
    
    # Si la voix est activ√©e, ajouter l'audio
    if context.user_data.get('voice_enabled', False) and context.args:
        await explain_audio(update, context)

# Fonction principale
def main():
    """D√©marrer le bot avec ElevenLabs"""
    logger.info("üöÄ D√©marrage du bot avec synth√®se vocale ElevenLabs...")
    logger.info(f"üìö Repository : {GITHUB_REPO}")
    
    try:
        # Cr√©er l'application
        app = Application.builder().token(TELEGRAM_TOKEN).build()
        
        # Handlers de base
        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("sync", sync_github))
        app.add_handler(CommandHandler("list", list_docs))
        app.add_handler(CommandHandler("search", search_in_docs))
        app.add_handler(CommandHandler("analyze", analyze_docs))
        
        # Handlers vocaux
        app.add_handler(CommandHandler("explain_audio", explain_audio))
        app.add_handler(CommandHandler("summary_audio", summary_audio))
        app.add_handler(CommandHandler("read", read_document))
        app.add_handler(CommandHandler("voice", voice_toggle))
        
        # Handlers avec option vocale
        app.add_handler(CommandHandler("summary", summary_with_voice))
        app.add_handler(CommandHandler("explain", explain_with_voice))
        
        # Autres handlers
        app.add_handler(CommandHandler("quiz", quiz_command))
        app.add_handler(CommandHandler("flashcards", flashcards_command))
        app.add_handler(CommandHandler("mindmap", mindmap_command))
        
        # Messages
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, answer_question))
        app.add_handler(MessageHandler(filters.VOICE, handle_voice))
        
        # D√©marrer
        logger.info("‚úÖ Bot avec synth√®se vocale d√©marr√© !")
        app.run_polling(allowed_updates=Update.ALL_TYPES)
        
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale : {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()